

# Using/fine-tune SAM for some special tasks

  **Learnable Ophthalmology SAM**[[Paper]](https://arxiv.org/pdf/2304.13425.pdf)[[Code]](https://github.com/Qsingle/LearnablePromptSAM)
  
  Added some learnable layers for eye disease diagnosis
  
  **Segment anything, from space?**[[Paper]](https://arxiv.org/pdf/2304.13000.pdf)
  
  In this work, it examines whether SAM’s impressive performance extends to overhead imagery problems.
  "SAM performs very poorly on both Road Segmentation and Parcel Delineation. It is also notable that the Parcel Delineation problem is challenging overall; "
  
  **Generalist Vision Foundation Models for Medical Imaging: A Case Study of
Segment Anything Model on Zero-Shot Medical Segmentation**[[paper]](https://arxiv.org/pdf/2304.12637.pdf)

It examines the recent Segment Anything Model (SAM)
on medical images, covering various imaging
modalities.（OCT/MRI/CT）

**Application of Segment Anything Model for Civil 
Infrastructure Defect Assessment**

This research assesses the performance of two deep learning models, SAM and U-Net, for detecting 
cracks in concrete structures. 

**Segment Anything in Medical Images**[[paper]](https://arxiv.org/pdf/2304.12306.pdf)

 Fine-tuning SAM for medical image segmentation. We freeze the image encoder and prompt encoder and only fine-tune the mask decoder.


**When SAM Meets Medical Images: An Investigation
of Segment Anything Model (SAM) on Multi-phase
Liver Tumor Segmentation**[[paper]](https://arxiv.org/pdf/2304.08506.pdf)

 
 # Input Augmentation
 
 
 **Input Augmentation with SAM: Boosting
Medical Image Segmentation with Segmentation
Foundation Model**[[paper]](https://arxiv.org/pdf/2304.11332.pdf)

 
 # Vidieo
 
 **Track Anything: Segment Anything Meets Videos**[[paper]](https://arxiv.org/pdf/2304.11968.pdf)
 
 

  
